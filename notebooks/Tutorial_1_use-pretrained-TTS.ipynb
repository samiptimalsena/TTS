{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45ea3ef5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Easy Inferencing with ðŸ¸ TTS âš¡\n",
    "\n",
    "#### You want to quicly synthesize speech using Coqui ðŸ¸ TTS model?\n",
    "\n",
    "ðŸ’¡: Grab a pre-trained model and use it to synthesize speech using any speaker voice, including yours! âš¡\n",
    "\n",
    "ðŸ¸ TTS comes with a list of pretrained models and speaker voices. You can even start a local demo server that you can open it on your favorite web browser and ðŸ—£ï¸ .\n",
    "\n",
    "In this notebook, we will: \n",
    "```\n",
    "1. List available pre-trained ðŸ¸ TTS models\n",
    "2. Run a ðŸ¸ TTS model\n",
    "3. Listen to the synthesized wave ðŸ“£\n",
    "4. Run multispeaker ðŸ¸ TTS model \n",
    "```\n",
    "So, let's jump right in!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5c2a5-46eb-42fd-b550-2a052546857e",
   "metadata": {},
   "source": [
    "## Install ðŸ¸ TTS â¬‡ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2aec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U pip\n",
    "! pip install TTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c07a273",
   "metadata": {},
   "source": [
    "## âœ… List available pre-trained ðŸ¸ TTS models\n",
    "\n",
    "Coqui ðŸ¸TTS comes with a list of pretrained models for different model types (ex: TTS, vocoder), languages, datasets used for training and architectures. \n",
    "\n",
    "You can either use your own model or the release models under ðŸ¸TTS.\n",
    "\n",
    "Use `tts --list_models` to find out the availble models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608d203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Name format: type/language/dataset/model\r\n",
      " 1: tts_models/multilingual/multi-dataset/your_tts\r\n",
      " 2: tts_models/en/ek1/tacotron2\r\n",
      " 3: tts_models/en/ljspeech/tacotron2-DDC\r\n",
      " 4: tts_models/en/ljspeech/tacotron2-DDC_ph\r\n",
      " 5: tts_models/en/ljspeech/glow-tts\r\n",
      " 6: tts_models/en/ljspeech/speedy-speech\r\n",
      " 7: tts_models/en/ljspeech/tacotron2-DCA\r\n",
      " 8: tts_models/en/ljspeech/vits\r\n",
      " 9: tts_models/en/ljspeech/fast_pitch\r\n",
      " 10: tts_models/en/vctk/vits\r\n",
      " 11: tts_models/en/vctk/fast_pitch\r\n",
      " 12: tts_models/en/sam/tacotron-DDC\r\n",
      " 13: tts_models/en/blizzard2013/capacitron-t2-c50\r\n",
      " 14: tts_models/en/blizzard2013/capacitron-t2-c150\r\n",
      " 15: tts_models/es/mai/tacotron2-DDC\r\n",
      " 16: tts_models/fr/mai/tacotron2-DDC\r\n",
      " 17: tts_models/uk/mai/glow-tts\r\n",
      " 18: tts_models/zh-CN/baker/tacotron2-DDC-GST\r\n",
      " 19: tts_models/nl/mai/tacotron2-DDC\r\n",
      " 20: tts_models/de/thorsten/tacotron2-DCA\r\n",
      " 21: tts_models/de/thorsten/vits\r\n",
      " 22: tts_models/ja/kokoro/tacotron2-DDC\r\n",
      " 23: tts_models/tr/common-voice/glow-tts\r\n",
      " 24: tts_models/it/mai_female/glow-tts\r\n",
      " 25: tts_models/it/mai_female/vits\r\n",
      " 26: tts_models/it/mai_male/glow-tts\r\n",
      " 27: tts_models/it/mai_male/vits\r\n",
      " 28: tts_models/ewe/openbible/vits\r\n",
      " 29: tts_models/hau/openbible/vits\r\n",
      " 30: tts_models/lin/openbible/vits\r\n",
      " 31: tts_models/tw_akuapem/openbible/vits\r\n",
      " 32: tts_models/tw_asante/openbible/vits\r\n",
      " 33: tts_models/yor/openbible/vits\r\n",
      " 1: vocoder_models/universal/libri-tts/wavegrad\r\n",
      " 2: vocoder_models/universal/libri-tts/fullband-melgan\r\n",
      " 3: vocoder_models/en/ek1/wavegrad\r\n",
      " 4: vocoder_models/en/ljspeech/multiband-melgan\r\n",
      " 5: vocoder_models/en/ljspeech/hifigan_v2\r\n",
      " 6: vocoder_models/en/ljspeech/univnet\r\n",
      " 7: vocoder_models/en/blizzard2013/hifigan_v2\r\n",
      " 8: vocoder_models/en/vctk/hifigan_v2\r\n",
      " 9: vocoder_models/en/sam/hifigan_v2\r\n",
      " 10: vocoder_models/nl/mai/parallel-wavegan\r\n",
      " 11: vocoder_models/de/thorsten/wavegrad\r\n",
      " 12: vocoder_models/de/thorsten/fullband-melgan\r\n",
      " 13: vocoder_models/ja/kokoro/hifigan_v1\r\n",
      " 14: vocoder_models/uk/mai/multiband-melgan\r\n",
      " 15: vocoder_models/tr/common-voice/hifigan\r\n"
     ]
    }
   ],
   "source": [
    "! tts --list_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9dd7ab",
   "metadata": {},
   "source": [
    "## âœ… Run a ðŸ¸ TTS model\n",
    "\n",
    "#### **First things first**: Using a release model and default vocoder:\n",
    "\n",
    "You can simply copy the full model name from the list above and use it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9e4608-16ec-4dcd-bd6b-bd10d62286f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading model to /home/maspi/.local/share/tts/tts_models--en--ljspeech--glow-tts\n",
      " > Model's license - MPL\n",
      " > Check https://www.mozilla.org/en-US/MPL/2.0/ for more info.\n",
      " > Downloading model to /home/maspi/.local/share/tts/vocoder_models--en--ljspeech--multiband-melgan\n",
      " > Model's license - MPL\n",
      " > Check https://www.mozilla.org/en-US/MPL/2.0/ for more info.\n",
      " > Using model: glow_tts\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.1\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Vocoder Model: multiband_melgan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/home/maspi/.local/share/tts/vocoder_models--en--ljspeech--multiband-melgan/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: multiband_melgan_generator\n",
      " > Discriminator Model: melgan_multiscale_discriminator\n",
      " > Text: hello world\n",
      " > Text splitted to sentences.\n",
      "['hello world']\n",
      " > Processing time: 0.2603609561920166\n",
      " > Real-time factor: 0.18835167598536634\n",
      " > Saving output to output.wav\n"
     ]
    }
   ],
   "source": [
    "!tts --text \"hello world\" \\\n",
    "--model_name \"tts_models/en/ljspeech/glow-tts\" \\\n",
    "--out_path output.wav\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2cb14-1aba-400e-a219-8ce44d9410be",
   "metadata": {},
   "source": [
    "## ðŸ“£ Listen to the synthesized wave ðŸ“£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe63ef4-9284-4461-9dda-1ca7483a8f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"output.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67d178-1ebe-49c7-9a47-0593251bdb96",
   "metadata": {},
   "source": [
    "### **Second things second**:\n",
    "\n",
    "ðŸ”¶ A TTS model can be either trained on a single speaker voice or multispeaker voices. This training choice is directly reflected on the inference ability and the available speaker voices that can be used to synthesize speech. \n",
    "\n",
    "ðŸ”¶ If you want to run a multispeaker model from the released models list, you can first check the speaker ids using `--list_speaker_idx` flag and use this speaker voice to synthesize speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b18839-f750-4a61-bbb0-c964acaecab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the possible speaker IDs.\n",
    "!tts --model_name \"tts_models/en/vctk/vits\" \\\n",
    "--list_speaker_idxs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4365a9d-f922-4b14-88b0-d2b22a245b2e",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Synthesize speech using speaker ID ðŸ’¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be0403-d13e-4d9b-99c2-c10b85154063",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tts --text \"Trying out specific speaker voice\"\\\n",
    "--out_path spkr-out.wav --model_name \"tts_models/en/vctk/vits\" \\\n",
    "--speaker_idx \"p341\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894a560a-f9c8-48ce-aaa6-afdf516c01f6",
   "metadata": {},
   "source": [
    "## ðŸ“£ Listen to the synthesized speaker specific wave ðŸ“£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed485b0a-dfd5-4a7e-a571-ebf74bdfc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"spkr-out.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84636a38-097e-4dad-933b-0aeaee650e92",
   "metadata": {},
   "source": [
    "ðŸ”¶ If you want to use an external speaker to synthesize speech, you need to supply `--speaker_wav` flag along with an external speaker encoder path and config file, as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb15fa-123a-4282-a127-87b50dc70365",
   "metadata": {},
   "source": [
    "First we need to get the speaker encoder model, its config and a referece `speaker_wav`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f1b13-560c-4fed-bafd-e38ec9712359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/coqui-ai/TTS/releases/download/speaker_encoder_model/config_se.json\n",
    "!wget https://github.com/coqui-ai/TTS/releases/download/speaker_encoder_model/model_se.pth.tar\n",
    "!wget https://github.com/coqui-ai/TTS/raw/speaker_encoder_model/tests/data/ljspeech/wavs/LJ001-0001.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac1912-5054-4a68-8357-6d20fd99cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tts --model_name tts_models/multilingual/multi-dataset/your_tts \\\n",
    "--encoder_path model_se.pth.tar \\\n",
    "--encoder_config config_se.json \\\n",
    "--speaker_wav LJ001-0001.wav \\\n",
    "--text \"Are we not allowed to dim the lights so people can see that a bit better?\"\\\n",
    "--out_path spkr-out.wav \\\n",
    "--language_idx \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ddce58-8aca-4f69-84c3-645ae1b12e7d",
   "metadata": {},
   "source": [
    "## ðŸ“£ Listen to the synthesized speaker specific wave ðŸ“£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc889adc-9c71-4232-8e85-bfc8f76476f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(\"spkr-out.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29101d01-0b01-4153-a216-5dae415a5dd6",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations! ðŸŽ‰ You now know how to use a TTS model to synthesize speech! \n",
    "Follow up with the next tutorials to learn more adnavced material."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
